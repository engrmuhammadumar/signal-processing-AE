{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory\n",
    "main_dir = r'D:\\Grinding Machine\\Vibration_Data\\2nd_round'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specific keys\n",
    "keys = ['BF', 'BL', 'N', 'TF']\n",
    "\n",
    "# Initialize the mat_data dictionary with these keys\n",
    "mat_data = {key: [] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each subdirectory in the main directory\n",
    "for sub_dir in os.listdir(main_dir):\n",
    "    # Construct the path to the subdirectory\n",
    "    sub_dir_path = os.path.join(main_dir, sub_dir)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(sub_dir_path):\n",
    "        # Iterate through each file in the subdirectory\n",
    "        for file in os.listdir(sub_dir_path):\n",
    "            # Check if the file is a .mat file\n",
    "            if file.endswith('.mat'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(sub_dir_path, file)\n",
    "\n",
    "                # Load the .mat file\n",
    "                mat_contents = scipy.io.loadmat(file_path)\n",
    "                \n",
    "\n",
    "                signal = mat_contents['signals'][0]\n",
    "\n",
    "\n",
    "             \n",
    "                mat_data[sub_dir].append(signal)\n",
    "                \n",
    "\n",
    "# Now mat_data contains the contents of all .mat files in the subdirectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat_data['BF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mat_data.keys():\n",
    "    # This concatenates all arrays in the list into one array, then flattens it\n",
    "    mat_data[key] = np.concatenate(mat_data[key]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mat_data['BF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 25600  # Length of each segment\n",
    "overlap = int(segment_length * 0.35)  # 75% overlap\n",
    "\n",
    "segmented_data = {}  # Dictionary to store segmented signals\n",
    "\n",
    "for key, signal in mat_data.items():\n",
    "    # Initialize a list to store segments for this key\n",
    "    segments = []\n",
    "    \n",
    "    # Start index for the first segment\n",
    "    start_idx = 0\n",
    "    \n",
    "    # Calculate the number of segments we can extract\n",
    "    while start_idx + segment_length <= len(signal):\n",
    "        # Extract a segment\n",
    "        segment = signal[start_idx:start_idx + segment_length]\n",
    "        segments.append(segment)\n",
    "        \n",
    "        # Update start index for the next segment, accounting for the new overlap\n",
    "        # This effectively moves the start index by 25% of the segment length each time\n",
    "        start_idx += segment_length - overlap  # Move start index by 25% of segment length for 75% overlap\n",
    "    \n",
    "    # Store the list of segments in the new dictionary\n",
    "    segmented_data[key] = segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segmented_data['BF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scalogram(signal, fs):\n",
    "    scales = np.arange(1, 128)\n",
    "    wavelet = 'morl'\n",
    "    coefficients, _ = pywt.cwt(signal, scales, wavelet, 1.0 / fs)\n",
    "    return np.abs(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'D:\\Grinding Machine\\Vib CWT'  # Replace with your main directory path # Initialize your dictionary\n",
    "\n",
    "\n",
    "# Your existing code to populate mat_data...\n",
    "\n",
    "# Now, iterate over the dictionary and create scalograms\n",
    "\n",
    "scales = np.arange(1, 128)\n",
    "for class_name, signals in segmented_data.items():\n",
    "    class_dir = os.path.join(main_dir, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    for i, signal in enumerate(signals):\n",
    "\n",
    "        scalogram = create_scalogram(signal, 25600)  # Replace 25600 with actual fs if different\n",
    "        plt.imshow(scalogram, extent=[0, len(signal) / 25600, 1, max(scales)], cmap='jet', aspect='auto')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        print(i)\n",
    "\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(os.path.join(class_dir, f'scalogram_2nd_round_{i}.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
